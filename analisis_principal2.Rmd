---
title: "Análisis Principal"
author: "Manuela Lopez Cambron, 1673688"
date: "`r Sys.Date()`"
output: pdf_document
---
```{r}
library(pROC)
library(dplyr)
library(car)
library(marginaleffects)
library(broom)
library(margins)
library(ggplot2)
library(forcats)
library(modelsummary)
```

```{r}
df <- read.csv("prado_variables.csv", stringsAsFactors = TRUE)

df$sop_montaje <- as.factor(df$sop_montaje)
df$serie <- as.factor(df$serie)

str(df)
```

# ANÁLISIS PRINCIPAL

Primeramente generamos la submuestra de la población aplicando la regla estructural de 'cuadrado'.
```{r}
# 0) Regla estructural: excluir "cuadrado"
df <- subset(df, orientacion != "cuadrado")
df$orientacion <- droplevels(df$orientacion)
dim(df)
```

Continuamos con un total de 7002 pinturas

Fijamos también los niveles de referencia para las variables factor. El nivel más frecuente como referencia para todos los factores a excepción de "tam_cat" donde por interpretabilidad se define la referencia en 'pequeno' y las variables binarias "sop_montaje" y "serie" donde se fija el valor "no"
```{r}
# 1) Niveles de los factores binarios 
df$sop_montaje <- factor(df$sop_montaje, levels = c(0, 1), labels = c("no", "si"))
df$serie       <- factor(df$serie,       levels = c(0, 1), labels = c("no", "si"))

# 2) tam_cat nominal con referencia "pequeno"
df$tam_cat <- factor(df$tam_cat, levels = c("pequeno", "mediano", "grande"))
df$tam_cat <- relevel(df$tam_cat, ref = "pequeno")

# 3) Binarios con referencia "no"
df$sop_montaje <- relevel(df$sop_montaje, ref = "no")
df$serie       <- relevel(df$serie, ref = "no")

# 4) Referencias = nivel más frecuente (para el resto de factores)
ref_orientacion <- names(sort(table(df$orientacion), decreasing = TRUE))[1]
df$orientacion  <- relevel(df$orientacion, ref = ref_orientacion)

ref_soporte <- names(sort(table(df$soporte_grp), decreasing = TRUE))[1]
df$soporte_grp <- relevel(df$soporte_grp, ref = ref_soporte)

ref_tecnica <- names(sort(table(df$tecnica), decreasing = TRUE))[1]
df$tecnica  <- relevel(df$tecnica, ref = ref_tecnica)

ref_autor <- names(sort(table(df$tipo_autor), decreasing = TRUE))[1]
df$tipo_autor <- relevel(df$tipo_autor, ref = ref_autor)

ref_tema <- names(sort(table(df$tema), decreasing = TRUE))[1]
df$tema <- relevel(df$tema, ref = ref_tema)

str(df)
```

## Efectos principales

Para determinar los efectos principales del modelo se seguirá la estructura por bloques definida en al sección de metodología

**Modelo nulo**

Como punto de partida se ajustó un modelo nulo (solos intercepto), sin covariables. Este modelo proporcionará la referencia sobre el cual iremos cuantificando el aporte de los bloques que se añadirán sucesivamente. En un modelo binario como el nuestro, el intercepto del modelo nulo estima la probabilidad media de éxito en la muestra. Recordemos que estaremos trabajando en todo momento con la sub-muestra no-cuadrado.

```{r}
# Modelo nulo (solo intercepto)
m0 <- glm(exito ~ 1, data = df, family = binomial(link = "logit"))

# Resumen del modelo
cat("\nResumen del modelo:\n")
summary(m0)

# Probabilidad media estimada de éxito (a partir del intercepto)
cat("\nProbabilidad estimada de éxito:\n")
p0 <- plogis(coef(m0)[1])
p0
```

**Bloque 1: Datación y control de incertidumbre**

Se incorpora la variable "fecha_est" y su covariable de incertidumbre "fecha_ancho", comparando especificación lineal vs flexible (spline) en ambas variables.

Comenzaremos decidiendo la especificación del control "fecha_ancho".

```{r}
library(splines)

# Transformación log1p(fecha_ancho)
df$log_ancho <- log1p(df$fecha_ancho)

# Modelo A: control lineal en log_ancho
m1_lin <- glm(exito ~ ns(fecha_est, 3) + log_ancho,
              data = df, family = binomial(link = "logit"))

# Modelo B: control flexible (spline) en log_ancho
m1_spl <- glm(exito ~ ns(fecha_est, 3) + ns(log_ancho, 3),
              data = df, family = binomial(link = "logit"))

# Resúmenes (por si aparecen warnings / coeficientes raros / SE enormes)
cat("\nResumen del modelo m1_lin (control lineal):\n")
summary(m1_lin)
cat("\nResumen del modelo m1_spl (control flexible spline):\n")
summary(m1_spl)
```

Comprobamos la aportación del bloque comparando ambas especificaciones con el modelo nulo:

```{r}
# Comparación --> aporte del Bloque 1

# Información
cat("\nAporte de información del Bloque 1 (control lineal):\n")
anova(m0, m1_lin, test="Chisq")
cat("\nAporte de información del Bloque 1 (control flexible spline):\n")
anova(m0, m1_spl, test="Chisq")

# Complejidad
cat("\nAporte de complejidad:\n")
AIC(m0, m1_lin, m1_spl)
BIC(m0, m1_lin, m1_spl)
```

Comparamos también las dos formas funcionales del control mediante modelos anidados:

```{r}
# Comparación --> formas funcionales
cat("\nAporte de información entre opciones (m1_lin vs m1_spl)\n")
anova(m1_lin, m1_spl, test="Chisq")
```

El aporte del bloque 1 es claramente significativo. Ambas especificaciones mejoraron significativamente el modelo nulo (LRT $p=9.933e-11$, $p=3.085e-10$). Sin embargo, la especificación flexible para el control "fecha_ancho" no proporcionó mejora adicional frente a la lineal (LRT $p = 0.2026$) y presentó peor ajuste penalizado por complejidad (AIC y BIC mayores). Por esta razón, se adoptó para los modelos posteriores la especificación lineal $log(1+fecha\_ancho)$ como ajuste definitivo del control de incertidumbre en la datación. 

Finalmente comprobaremos las formas funcionales de "fecha_est" para ver si la especificación flexible de esta variable es realmente necesaria para nuestro modelo o no. 

```{r}
m1_lin_fecha <- glm(exito ~ fecha_est + log_ancho,
              data = df, family = binomial(link = "logit"))
```

```{r}
# Comparación
# Información
cat("\nAporte de la opción fecha_est felxible:\n")
anova(m1_lin_fecha, m1_lin, test="Chisq")

# Complejidad
cat("\nComplejidad de la opción fecha_est flexible:\n")
AIC(m1_lin,m1_lin_fecha)
BIC(m1_lin,m1_lin_fecha)
```

Vemos que la especificación felxible es preferible frente a la lineal en terminos de LRT ($p=0.049)$ como AIC ($\triangle AIC \approx -2$). Sin embargo la mejora de AIC es débil frente a una fuerte penalización en BIC ($\triangle AIC \approx -2$ vs $\triangle BIC \approx 12$). Teniendo en cuenta nuestro objetivo descriptivo, y no predictivo, decidimos seleccionar la versión lineal por facilidad interpretativa. Por otro lado, también seleccionamos esta opción por ser más conservadora, ya que añadimos menos parámetros al modelo (2 parámetros menos), y és preferible dado que la mayoría de las futuras covariables són facotres y nuestra variables respuesta está fuertemente desbalanceada. Sin embargo, dejamos constancia del hecho que la especificación flexible con spline par fecha_est podría ser considerada para análisis más exaustivos. 

Modelo resultante después de añadir Bloque 1:
```{r}
m1 <- m1_lin_fecha
```

**Bloque 2: Morfología**

Se incorporan las variables morfológicas de tamaño i formato, "area" y "orientación" respectivamente. Se evaluará si aportan infomración adiciona, una vez controlado el efecto de datación (bloque 1). La variable "area" se introducirá mediante una transformación logarítmica $log(area)$, pudiendo llegar a ser tratada de manera flexible si fuera necesario. También se proporcinará un modelo secundario sustituyendo "area" por "tam_cat" (categorización de área), y se compararán. Se decidirá el mejor modelo siguiendo las idicaciones de la sección de metodología, que resumidamente dictan lo siguiente: 

- si "area" presenta problemas o no mejora sustancialmente más que "tam_cat", permitimos ajuste flexible (spline) y si no funciona elejimos "tam_cat"

- si "area" mejora sustanciamente más que "tam_cat", elejimos "area"

- si "area" y "tam_cat" proporcionan resultados cualitativamente iguales, elejimos "area" pero manteniendo el modelo secundario "tam_cat" para interpretaciones claras.

```{r}
# Trnasformación log(area)
df$log_area <- log(df$area)

# BLOQUE 2 (principal candidato): log(area) + orientacion
m2_area <- update(m1, . ~ . + log_area + orientacion)

# BLOQUE 2 (secundario): tam_cat + orientacion
m2_tamcat <- update(m1, . ~ . + tam_cat + orientacion)

# Resúmenes (por si aparecen warnings / coeficientes raros / SE enormes)
cat("\nResumen del modelo m2_area (+ log_area + orientacion):\n")
summary(m2_area)

cat("\nResumen del modelo m2_tamcat (+ tam_cat + orientacion):\n")
summary(m2_tamcat)

# Comparación --> aporte del Bloque 2

# Información
cat("\nAporte de información del Bloque 2 (tamaño continuo):\n")
anova(m1, m2_area, test="Chisq")

cat("\nAporte de información del Bloque 2 (tamaño categórico):\n")
anova(m1, m2_tamcat, test="Chisq")

# Complejidad
cat("\nAporte de complejidad:\n")
AIC(m1, m2_area, m2_tamcat)
BIC(m1, m2_area, m2_tamcat)
```


Ambas opciones del tamaño (log(area) continua vs. tam_cat categórica) aportan información adicional tras controlar la datación (LRT $p< 2.2e-16$ en mabos casos). Sin embargo, la especificación categórica presenta mejor ajuste–complejidad con AIC y BIC sustancialmente menores (AIC: 5058 vs 5000; BIC: 5092 vs 5042). 

Antes de seleccionar "tam_cat" debemos tener en cuenta que podría haber una relación no lineal que actualmente $log(area)$ no esta pudiendo capturar. Por esta razón y dado que "area" ha demostrado mejorar el ajuste, frente al modelo anterior (m1), flexibilizaremos su especificacion (spline) y entonces volveremos a comparar con "tam_cat", para asegurar una decisión justa y cerrada.

```{r}
# Version flexible de log(area)
m2_area_spl <- update(m1, . ~ . + splines::ns(log_area, 3) + orientacion)

# Resúmenes (por si aparecen warnings / coeficientes raros / SE enormes)
summary(m2_area_spl)

# Comparaciones
cat("\nAporte de la opción log(area) flexible")
anova(m1, m2_area_spl, test="Chisq")

cat("\nComplejidad de la opción log(area) flexible")
AIC(m2_area, m2_area_spl, m2_tamcat)
BIC(m2_area, m2_area_spl, m2_tamcat)
```

El modelo con $log(area)$ lineal mejoró el ajuste, y al permitir no linealidad, el ajuste mejoró frente al lineal (AIC: 5021 vs 5058). Sin embargo, la especificación categórica "tam_cat" presentó el mejor compromiso ajuste–complejidad, con AIC y BIC claramente inferiores (AIC: 5000 vs 5021); BIC: 5041 vs 5069), superando también a la versión flexible del tamaño continuo. Por ello, se seleccionó "tam_cat" como representación principal del tamaño para los modelos posteriores.  

También se considera manejar en un modelo alternativo la opción de especificación continua del tamaño en versión lineal ($log(area)$ sin spline). El único obejtivo de mantener esta opción como alternativa, en vez de la flexible, es el de aportar un modelo más parsimonioso. Aunque su versión flexible mostró un mejor ajuste, no cumple con nuestro objetivo. Vemos que log(area) añade 1 parámetro (uno menso que "tam_cat") mientras que ns(log(area),3) añade 3 parámetros (uno más que "tam_cat").

Modelo resultante después de añadir Bloque 2:
```{r}
m2 <- m2_tamcat
```

Opción alternativa: especificación continua del tamaño en versión lineal ($log(area)$)

**Bloque 3: Material y técnica**

Se incorporan las variables "soporte" y "tecnica" para evaluar si aportan infomración adicional en conjunto, una vez controlados los efectos de datación (Bloque 1) y morfología (Bloque 2).  Se evaluará adicionalmente la inclusión de "sop_montaje" como extensión del bloque 3, comparando el modelo con y sin dicha covariable. 
```{r}
# BLOQUE 3 (versión base): soporte + técnica
m3_base <- update(m2, . ~ . + soporte_grp + tecnica)

# Resúmenes (por si aparecen warnings / coeficientes raros / SE enormes)
cat("\nResumen del modelo m3_base (soporte_grp + tecnica):\n")
summary(m3_base)

# Comparación--> aporte del Bloque 3

# Información
cat("\nAporte de información del Bloque 3:\n")
anova(m2, m3_base, test = "Chisq")

# Complejidad
cat("\nAporte de complejidad:\n")
AIC(m2, m3_base)
BIC(m2, m3_base)
```

La inclusión conjunta de "soporte_grp" y "tecnica" produjo una mejora significativa respecto al modelo con datación y morfología (LRT $p = 0.0003$) también mejoró el ajuste penalizado por AIC ($\triangle AIC \approx -13$), aunque el BIC aumentó ($\triangle BIC \approx +28$) (mayor penalización por el gran número de parámetros añadidos, 6 añadidos). Debido al objetivo descriptivo de nuestro estudio, se necide mantener el bloque por su relevancia teòrica y por la evidencia global de aporte de información.

Extenderemos este bloque añadiendo ahora la variable "sop_montaje", de menos interés conceptual pero con posibles implicaciones en el modelo a nivel de control.

```{r}
# BLOQUE 3 (extendido): + sop_montaje
m3_montaje <- update(m3_base, . ~ . + sop_montaje)

# Resúmenes (por si aparecen warnings / coeficientes raros / SE enormes)
cat("\nResumen del modelo m3_montaje (+ sop_montaje):\n")
summary(m3_montaje)

# Comparación--> aporte de sop_montaje

# Información
cat("\nAporte de informacion de sop_montaje (m3_montaje vs m3_base):\n")
anova(m3_base, m3_montaje, test = "Chisq")

cat("\nComplejidad de sop_montaje:\n")
AIC(m2, m3_base, m3_montaje)
BIC(m2, m3_base, m3_montaje)
```

Se observó una mejora significativa del ajuste respecto al modelo sin esta covariable (LRT $p = 0.005$). El AIC disminuyó ($\triangle AIC \approx -5$), indicando una mejora del ajuste penalizado por complejidad, aunque el BIC aumentó ligeramente ($\triangle BIC \approx +1$), el incremento fue pequeño. Por tanto, se retuvo "sop_montaje" en el modelo para los bloques posteriores.

Sin embargo, debemos recordar que aunque el incremento en BIC para la incluión de "sop_montaje" fue pequeño, la inclusión de Bloque 3 ya produjo aumento fuerte en BIC por lo que la complejidad añadida de todo el bloque más el extra sí representa un valor sustancial ($\triangle _{total} BIC \approx +29$). Por esta razón se ha decidido contemplar como modelo alternativo la opción sin este bloque.

Modelo resultante después de añadir Bloque 3:
```{r}
m3 <- m3_montaje
```

Opción alternativa: modelo sin Bloque 3 (y sin "sop_montaje")

**Bloque 4: Iconografía**

Se incorpora la variable "tema" para evaluar si la iconografía de la pintura aporta información adicional sobre la probabilidad de exito, una vez controlados los efectos de datacion (Bloque 1), morfología (Bloque 2) y material/tecnica (Bloque 3). 

```{r}
# BLOQUE 4: + tema
m4 <- update(m3, . ~ . + tema)

# Resumen (por si aparecen warnings / coeficientes raros / SE enormes)
cat("\nResumen del modelo m4 (+ tema):\n")
summary(m4)

# Comparación--> aporte del Bloque 4
# Información
cat("\nAporte de información del Bloque 4:\n")
anova(m3, m4, test = "Chisq")

# Complejidad
cat("\nAporte de complejidad:\n")
AIC(m3, m4)
BIC(m3, m4)
```

El bloque iconográfico (tema) mejoró significativamente el ajuste (LRT $p = 0.001$) y redujo el AIC ($\triangle AIC \approx -9$), pero incrementó fuertemente el BIC ($\triangle BIC \approx +53$), reflejando un aumento importante de complejidad por el número de niveles de tema (se añaden 9 parámetros). Dado que el objetivo principal del estudio es caracterizar el éxito con un modelo parsimonioso y fácilmente interpretable, se decidió mantener como modelo principal el que excluye tema. 

Sin embargo, dado el interés interpretativo de de la iconografía, se mantiene el modelo con tema como análisis complementario específico para interpretar relaciones temáticas. 

Por lo tanto, el modelo resultante después del Bloque 4 es el 'm3' y la opción alternativa contempla la inclusión de "tema"

**Bloque 5: autoría y serie**

Se incorporan las variables "tipo_autor" y "serie" para evaluar si la información de autoría y pertenencia a serie aporta información adicional sobre la probabilidad de éxito, una vez controlados los efectos de datación (Bloque 1), morfología (Bloque 2) y material/técnica (Bloque 3)

```{r}
# BLOQUE 5: + tipo_autor + serie
m5 <- update(m3, . ~ . + tipo_autor + serie)

# Resumen (por si aparecen warnings / coeficientes raros / SE enormes)
cat("\nResumen del modelo m5 (+ tipo_autor + serie):\n")
summary(m5)

# Comparación--> aporte del Bloque 5
# Información
cat("\nAporte de información del Bloque 5:\n")
anova(m3, m5, test = "Chisq")

# Complejidad
cat("\nAporte de complejidad:\n")
AIC(m3, m5)
BIC(m3, m5)

```

El Bloque 5 (autoría y serie) mejoró significativamente el modelo previo (LRT $p=0.01$) y redujo el AIC ($\triangle AIC \approx -4$), aunque incrementó fuertemente el BIC ($\triangle BIC \approx +23$), reflejando un aumento de complejidad. En este caso podemos observar algo  interesante, los coeficientes pertenecientes a "tipo_autor" no serultaron significativos, mientras que el de "serie=1" sí. Esto reflexa que el efecto significativo dentro del bloque parece concentrarse en serie. Para confirmar este hecho, se evaluará la contribución independiente de cada variable, mediante modelos parciales, antes de tomar una decisión formal sobre el modelo principal.

```{r}
# modelos parciales del Bloque 5
m5_serie <- update(m3, . ~ . + serie)
m5_autor <- update(m3, . ~ . + tipo_autor)

# Comparaciones --> aportes de los mdoelos parciales dle Bloque 5
# Información
cat("\nAporte de información de 'serie':\n")
anova(m3, m5_serie, test="Chisq")
cat("\nAporte de información de 'tipo_autor':\n")
anova(m3, m5_autor, test="Chisq")

# Complejidad
cat("\nAporte de complejidad:\n")
AIC(m3, m5_serie, m5_autor, m5)
BIC(m3, m5_serie, m5_autor, m5)
```

Efectivamente la variable "serie" sí demostró aportar información adicional (LRT $p=0.003$) mejorando el AIC ($\triangle AIC \approx -6$) y manteniendo aproximadamente estable BIC, respecto al anterior modelo aceptado 'm3' y también reduciendo ambos criterios frente al modelo completo 'm5' ($\triangle AIC \approx -2$, $\triangle BIC \approx -23$). Por otro lado, "tipo_autor" no demostró aportar información adicional (LRT $p=0.26$) además de el que aporta los valores más elevados tanto en AIC como en BIC, superando incluso los del modelo completo 'm5'. Se decide prescindir de la variable "tipo_autor" y conservar el modelo únicamente con la inclusión de "serie".

Modelo resultante después de añadir Bloque 5:

```{r}
m5 <- m5_serie
```

**Resumen**

Después de evaluar los efectos principales, el modelo principal es el siguiente:
```{r}
m_final <- glm(
  exito ~ fecha_est + log_ancho +
    tam_cat + orientacion +
    soporte_grp + tecnica + sop_montaje +
    serie,
  data = df, family = binomial(link = "logit")
)
summary(m_final)
```













## Interacciones

Para decidir que variables son candidatas de entrar al modelo primero traeremos las conclusiones obre estas obtenidas en el análisis descriptivo. En dicha sección de determinó que las más plausibles era "soporte_grp x fecha_est", "tecnica x fecha_est", "soporte_grp x tam_cat", "tecnica x tam_cat" y "soporte_grp x orientacion". Graficaremos los correspondientes gráficos de interacción para estas opciones y seleccionaremos las mejores, que seguidamente serán comprobadas con pruebas formales.

**Gráficos de interacción**

Graficamos $P(exito=1)$ predicha por el modelo, fijando el resto de covariables en valores de referencia/mediana.

```{r}
# niveles de referencia factores ([1] porque ya se especificó al inicio del análisis)
ref_tam_cat      <- levels(df$tam_cat)[1]
ref_orientacion  <- levels(df$orientacion)[1]
ref_soporte_grp  <- levels(df$soporte_grp)[1]
ref_tecnica      <- levels(df$tecnica)[1]
ref_sop_montaje  <- levels(df$sop_montaje)[1]
ref_serie        <- levels(df$serie)[1]

# niveles de referencia numéricas (mediana)
fecha0     <- median(df$fecha_est)
log_ancho0 <- median(df$log_ancho)
```

1) soporte_grp x fecha_est

```{r}
# =========================================================
# 1) soporte_grp × fecha_est
# =========================================================
m_int_SopFecha <- glm(
  exito ~ fecha_est + log_ancho +
    tam_cat + orientacion +
    soporte_grp + tecnica + sop_montaje +
    serie +
    soporte_grp:fecha_est,
  data = df, family = binomial(link = "logit")
)

x <- seq(min(df$fecha_est, na.rm = TRUE), max(df$fecha_est, na.rm = TRUE), length.out = 200)
lev <- levels(df$soporte_grp)

nd <- expand.grid(
  fecha_est = x,
  soporte_grp = lev,
  KEEP.OUT.ATTRS = FALSE,
  stringsAsFactors = FALSE
)

nd$log_ancho   <- log_ancho0
nd$tam_cat     <- ref_tam_cat
nd$orientacion <- ref_orientacion
nd$tecnica     <- ref_tecnica
nd$sop_montaje <- ref_sop_montaje
nd$serie       <- ref_serie

eta <- predict(m_int_SopFecha, newdata = nd, type = "link")

plot(range(x), range(eta), type = "n",
     xlab = "fecha_est", ylab = "logit{P(exito=1)}",
     main = "Interacción: soporte_grp × fecha_est (escala logit)")

for (i in seq_along(lev)) {
  idx <- nd$soporte_grp == lev[i]
  lines(nd$fecha_est[idx], eta[idx], lty = i, lwd = 2)
}
legend("bottomright", legend = lev, lty = seq_along(lev), lwd = 2, bty = "n")
```

Esta interacción plantea algunas preguntas, ya que aunque podemos observar algunos indicios vemos que existe una categoría, Tabla/Panel, que presenta una fuerte diferencia. Esto nos hace pensar en que puede tratarse de una escasez de datos en el extremo. 

Comprobamos frecuencias y recuento de éxitos por combinación:

```{r}
# Rangos observados por soporte
tapply(df$fecha_est, df$soporte_grp, range)

# Cortes de fecha_cat
grp_fecha <- cut(df$fecha_est,
breaks = c(1100, 1400, 1700, 2000),
include.lowest = TRUE)

cat("\nFrecuencias por combinación:\n")
xtabs(~ soporte_grp + grp_fecha, data = df)

cat("\nRecuento de éxitos por combinación:\n")
xtabs(exito ~ soporte_grp + grp_fecha, data = df)
```

Estos resultados explican la fomra rara del gráfico "soporte_grp x fecha_est". Vemos como en el tramo [1100, 1400] todo son frecuencias bajas y celdas vacías. Por esta razón el modelo interpreta que esas fechas la probabilidad de éxito es tan baja. Consecuentemente, decidimos descartar esta interacción por inconsistencia de resultados resultantes de extrapolación del modelo en regiones sin datos.

2) tenica x fecha_est

```{r}
# =========================================================
# 2) tecnica × fecha_est
# =========================================================
m_int_TecFecha <- glm(
  exito ~ fecha_est + log_ancho +
    tam_cat + orientacion +
    soporte_grp + tecnica + sop_montaje +
    serie +
    tecnica:fecha_est,
  data = df, family = binomial(link = "logit")
)

x <- seq(min(df$fecha_est, na.rm = TRUE), max(df$fecha_est, na.rm = TRUE), length.out = 200)
lev <- levels(df$tecnica)

nd <- expand.grid(
  fecha_est = x,
  tecnica = lev,
  KEEP.OUT.ATTRS = FALSE,
  stringsAsFactors = FALSE
)

nd$log_ancho   <- log_ancho0
nd$tam_cat     <- ref_tam_cat
nd$orientacion <- ref_orientacion
nd$soporte_grp <- ref_soporte_grp
nd$sop_montaje <- ref_sop_montaje
nd$serie       <- ref_serie

eta <- predict(m_int_TecFecha, newdata = nd, type = "link")

plot(range(x), range(eta), type = "n",
     xlab = "fecha_est", ylab = "logit{P(exito=1)}",
     main = "Interacción: tecnica × fecha_est (escala logit)")

for (i in seq_along(lev)) {
  idx <- nd$tecnica == lev[i]
  lines(nd$fecha_est[idx], eta[idx], lty = i, lwd = 2)
}
legend("bottomright", legend = lev, lty = seq_along(lev), lwd = 2, bty = "n")
```

Vemos indicios claros de interacción y un claro cruce: ólea pasa de estar por debajo a por encima. Sin embargo, estas observaciones podrían estar de nuevo sesgadas por falta de datos en algunos periodos. comporbamos recuentos:

```{r}
cat("\nFrecuencias por combinación:\n")
xtabs(~ tecnica + grp_fecha, data=df)

cat("\nRecuento de éxitos por combinación:\n")
xtabs(exito ~ tecnica + grp_fecha, data=df)
```
"
Efectivamente podemos ver como la variable "tecnica" está fuertemente sesgada debido al nivel 'oleo'. Aunque esta variable forma parte de nuestras hipótesis principales, su inclusión ya se aceptó de manera separada asumiendo un aumento de complejidad elevado (incremente significativo en BIC en Bloque 2 de efectos principales), por lo que su interés conceptual e interpretativo ya fue considerado. Por esta razón preferimos descartar su interacción

3) tecnica x tam_cat

```{r}
# =========================================================
# 3) tecnica × tam_cat
# =========================================================
m_int_TecTam <- glm(
  exito ~ fecha_est + log_ancho +
    tam_cat + orientacion +
    soporte_grp + tecnica + sop_montaje +
    serie +
    tecnica:tam_cat,
  data = df, family = binomial(link = "logit")
)

nd <- expand.grid(
  tam_cat = levels(df$tam_cat),
  tecnica = levels(df$tecnica),
  KEEP.OUT.ATTRS = FALSE,
  stringsAsFactors = FALSE
)

nd$fecha_est    <- fecha0
nd$log_ancho    <- log_ancho0
nd$orientacion  <- ref_orientacion
nd$soporte_grp  <- ref_soporte_grp
nd$sop_montaje  <- ref_sop_montaje
nd$serie        <- ref_serie

nd$eta <- predict(m_int_TecTam, newdata = nd, type = "link")

interaction.plot(x.factor = nd$tam_cat, trace.factor = nd$tecnica,
                 response = nd$eta, type = "b", pch = 19,
                 xlab = "tam_cat", ylab = "logit{P(exito=1)} ajustada",
                 main = "Interacción: tecnica × tam_cat (escala logit)")
```

De nuevo vemos puntos extremos de manera que comprobaremos recuentos:

```{r}
cat("\nFrecuencias por combinación:\n")
xtabs(~ tecnica + tam_cat, data=df)

cat("\nRecuento de éxitos por combinación:\n")
xtabs(exito ~ tecnica + tam_cat, data=df)
```

Obtenemos los mismo resultados en esta interacción con "tecnica": nivel 'oloe' fuertemente predominante. Se descarta esta interacción.

4) soporte_grp x tam_cat

```{r}
# =========================================================
# 4) soporte_grp × tam_cat
# =========================================================
m_int_SopTam <- glm(
  exito ~ fecha_est + log_ancho +
    tam_cat + orientacion +
    soporte_grp + tecnica + sop_montaje +
    serie +
    soporte_grp:tam_cat,
  data = df, family = binomial(link = "logit")
)

nd <- expand.grid(
  tam_cat     = levels(df$tam_cat),
  soporte_grp = levels(df$soporte_grp),
  KEEP.OUT.ATTRS = FALSE,
  stringsAsFactors = FALSE
)

nd$fecha_est    <- fecha0
nd$log_ancho    <- log_ancho0
nd$orientacion  <- ref_orientacion
nd$tecnica      <- ref_tecnica
nd$sop_montaje  <- ref_sop_montaje
nd$serie        <- ref_serie

nd$eta <- predict(m_int_SopTam, newdata = nd, type = "link")

interaction.plot(x.factor = nd$tam_cat, trace.factor = nd$soporte_grp,
                 response = nd$eta, type = "b", pch = 19,
                 xlab = "tam_cat", ylab = "logit{P(exito=1)} ajustada",
                 main = "Interacción: soporte_grp × tam_cat (escala logit)")
```

A primera vista podemos ver algunos incidios pero no determinantes de modificación del efecto. Podrían explicarse por la baja frecuencia de algunas combinaciones: 

```{r}
cat("\nFrecuencias por combinación:\n")
xtabs(~ soporte_grp + tam_cat, data=df)

cat("\nRecuento de éxitos por combinación:\n")
xtabs(exito ~ soporte_grp + tam_cat, data=df)
```

Efectivamente vemos que categorías como Metal-grande o Mural-pequeño presentan frecuencias realmente bajas, además los exitos se concentran alrededor de las categoría 'Lienzo' y 'Table/Panel' lo cual es lógico ya que són las categorías mayoritarias. Sin embargo se decide aceptar esta interacción como candidata para las posteriores pruebas formales, ya que es una hipótesis central del estudio.

5) soporte_grp x orientacion

```{r}
# =========================================================
# 5) soporte_grp × orientacion
# =========================================================
m_int_SopOri <- glm(
  exito ~ fecha_est + log_ancho +
    tam_cat + orientacion +
    soporte_grp + tecnica + sop_montaje +
    serie +
    soporte_grp:orientacion,
  data = df, family = binomial(link = "logit")
)

nd <- expand.grid(
  orientacion = levels(df$orientacion),
  soporte_grp = levels(df$soporte_grp),
  KEEP.OUT.ATTRS = FALSE,
  stringsAsFactors = FALSE
)

nd$fecha_est    <- fecha0
nd$log_ancho    <- log_ancho0
nd$tam_cat      <- ref_tam_cat
nd$tecnica      <- ref_tecnica
nd$sop_montaje  <- ref_sop_montaje
nd$serie        <- ref_serie

nd$eta <- predict(m_int_SopOri, newdata = nd, type = "link")

interaction.plot(x.factor = nd$orientacion, trace.factor = nd$soporte_grp,
                 response = nd$eta, type = "b", pch = 19,
                 xlab = "orientacion", ylab = "logit{P(exito=1)} ajustada",
                 main = "Interacción: soporte_grp × orientacion (escala logit)")

```

Esta interacción ha resultado la menos relevante, pero aun con incidios de posible interacción. Comprobaremos también los recuentos:

```{r}
cat("\nFrecuencias por combinación:\n")
xtabs(~ soporte_grp + orientacion, data=df)

cat("\nRecuento de éxitos por combinación:\n")
xtabs(exito ~ soporte_grp + orientacion, data=df)
```

Vemso el mismo patrón para la variable respuesta: los éxitos se concentran al rededor de 'Lienzo', sin embargo no vemos fuertes desbalances para los grupos de orientación. La mantenemos como posble candidata a pruebas

**Pruebas formales**

Decidimos testear las siguientes interacciones: "soporte_grp x tam_cat" y "soporte_grp x orientacion". Ambas opciones parecen plausibles tanto por su representación gráfica como por interpretación conceptual, además concretamente "soporte x tam_cat" se incluía en nuestras hipótesis, de manera que consideramos muy apropiada esta selección.

Comprobaremos en primer caso la inclusión de cada interacción de manera separada para estudiar si cada una por separado aporta información al modelo y su compromiso ajuste-complejidad.

```{r}
# soporte_grp x tam_cat
cat("\n==============================\n soporte_grp x tam_cat \n==============================\n")
m_soporte_tamcat <- update(m_final, . ~ . + soporte_grp:tam_cat)
anova(m_final, m_soporte_tamcat, test = "Chisq")
AIC(m_final, m_soporte_tamcat)
BIC(m_final, m_soporte_tamcat)

# soporte_grp x orientacion
cat("\n==============================\n soporte_grp x orientacion \n==============================\n")
m_soporte_orientacion <- update(m_final, . ~ . + soporte_grp:orientacion)
anova(m_final, m_soporte_orientacion, test = "Chisq")
AIC(m_final, m_soporte_orientacion)
BIC(m_final, m_soporte_orientacion)
```

Vemos que ambas interacciones demuestran mejorar significativamente el modelo aportando informacion (LRT($99%$) $p<0.01$) i reduciendo el AIC ($\triangle AIC \approx -7; -10$). Aunque el BIC aumento en los dos casos ($\triangle BIC \approx +47; +17$). Por interés interpretativo decidimos mantener el modelo con la interacción "soporte_grp x tam_cat" como base y procedemos a examinar el modelo completo anidado con la otra interacción. 

```{r}
m_completo <- update(m_soporte_tamcat, . ~ . + soporte_grp:orientacion)

anova(m_final, m_soporte_tamcat, test = "Chisq")
AIC(m_final, m_soporte_tamcat)
BIC(m_final, m_soporte_tamcat)
```

Vemos que la inclusión de la interacción "soporte_grp x orientación" sigue siendo significativa una vez controlado el efecto de "soporte_grp x tam_cat", sin embargo provoca un brave problema de complejidad ($\triangle BIC \approx +74$) que no consideramos aceptable ni necesario en este punto análisis. En consecuencia descartamos la interaccion con orientación una vez controlado por tamaño. Además ya detectamos anteriormente existencia de celdas problemáticas en soporte, que pueden provocar separación, por lo que algunos coeficientes pueden volverse fuertemente inestables. Por esta razón, debemos mencionar que la interacción con tamaño se mantendrá pero con interpretación principalmente en 'Lienzo' y 'Tabla/Panel', además de tratará de minimizar esta problematica en la siguiente sección.

Finalmente se decide definir el modelo principal con únicamente la interacción "soporte_grp x tam_cat" con el obejtivo de dar respuesta a nuestra hipótesis, pero teniendo en cuenta el fuerte aumento de BIC y la existencia de posible inestabilidad, se considera conservar el modelo sin interacciones como alternativo con el fin de explorar más rigurosamente los efectos principales, si se considera oportuno.

**Resumen**

Después de evaluar las interacciones, el modelo principal es el siguiente:

```{r}
m_completo <- glm(
  exito ~
    fecha_est + log_ancho +
    tam_cat + orientacion +
    soporte_grp + tecnica + sop_montaje +
    serie +
    soporte_grp:tam_cat,
  data = df,
  family = binomial(link = "logit")
)

summary(m_completo)
```

Y el modelo reducido conservado como alternativo, sin interacciones, es el siguiente:
```{r}
m_reducido <- glm(
  exito ~
    fecha_est + log_ancho +
    tam_cat + orientacion +
    soporte_grp + tecnica + sop_montaje +
    serie,
  data = df,
  family = binomial(link = "logit")
)
```

















## Diagnóstico de ajuste y correcciones

En esta sección se presentan diagnósticos preliminares del modelo, centrados en la calidad del ajuste y en la estabilidad de los parámetros, especialmente considerando la baja prevalencia del evento y el uso de múltiples factores e interacciones. No se llevaran a cabo aún procedimientos de validación formales, ya que se abordarán en secciones posteriores.

```{r}
y <- model.response(model.frame(m_completo))
E <- sum(y == 1)
N <- length(y)
p <- length(coef(m_completo))

cat("N =", N, "  Eventos (1) =", E, "  Prevalencia =", round(E/N, 4), "\n")
cat("Num coeficientes (incluye dummies) =", p, "\n")
cat("EPV aprox (eventos por coef) =", round(E/p, 3), "\n")

```

Con 7002 observaciones y 849 evento, el modelo dispone de información suficiente para estimar los 22 parámetros que contiene. El coeficiente de ($EPV \approx 38.6$) sugiere que el desnivel en la respuesta no plantea una limitación para el modelo seleccionado.

```{r}
Y <- xtabs(exito ~ soporte_grp + tam_cat, data = df)
N <- xtabs(~ soporte_grp + tam_cat, data = df)
P <- Y / N

cat("\nFrecuencias de soporte\n")
table(df$soporte_grp)
cat("\nFrecuencias de tamaño\n")
table(df$tam_cat)

cat("\nÉxitos Y:\n"); print(Y)
cat("\nTotales N:\n"); print(N)
cat("\nProporción P=Y/N:\n"); print(round(P, 3))

cat("\nCeldas con 0 éxitos (Y==0):\n")
print((Y == 0) & (N > 0))

cat("\nCeldas con todos éxitos (Y==N):\n")
print((Y == N) & (N > 0))
```

Las tablas de contingencia de exitos y totales por combinación de la interacción muestra celdas con respuestas deterministas lo que puede provocar separación. En concreto observamos todo éxitos en Mural-pequeño, lo cual tiene sentido conceptualmete ya que los murales estan asociados a grandes obras de arte; y observamso ausencia total de éxitos en Metal-mediano,grande y Otros-mediano,grande. Estos resultados eran esperables debido a la baja frecuencia de las categorías involucradas Metal/Mural/Otros. Recordamos entonces la importancia de centrar la interpretacion al rededor de las categoría estables Tabl/Panel y Lienzo, aun sabiendo que no estan ajenas a la problemática. 

```{r}
library(car)
vif(m_completo)
```

Los indicadores de colinealidad muestran valores muy altos para soporte_grp ($GVIF \approx 8.50$) y elevados para tam_cat:soporte_grp ($GVIF \approx 2.88$), en contraste con el resto de covariables, cuyos valores permanecen cercanos a 1. Esta evidencia afirma una dependencia fuerte entre los bloques de parámetros de los efectos principales y los de la interacción, especialmente en presencia de un diseño como el nuestro, desbalanceado entre niveles y con celdas con baja frecuencia.

```{r}
n <- nobs(m_completo)
p <- length(coef(m_completo))

cat("Devianza ajustada:",deviance(m_completo) / (n - p))
```

La evaluación del ajuste global mediante devianza ajustada no aporta indicios de sobredispersión ($\varphi \approx 0,706$), es proxima a 1. Por lo que estos resultados sugieren que no existe un exceso de variabilidad no explicada que justifique adoptar estrategias orientadas a corregir sobredispersión

Después de este primer análisis vemos que existen dos problematicas que debemos manejar, la separación por celdas vacías y la colinealidad excesiva en soporte. 

Primeramente abordaremos la problemática provocada por las celdas deterministas de la interacción y más adelante, si la colinealidad siguiera presente, se adoptarán nuevas medidas. 

**Separación**

Contrastaremos formalmente la existencia de separación en nuestro modelo:

```{r}
df2 <- df
df2$exito <- if (is.factor(df2$exito)) as.integer(df2$exito == levels(df2$exito)[2]) else as.integer(df2$exito)

m_df2 <- update(m_completo, data = df2)

X <- model.matrix(m_df2)
y <- model.response(model.frame(m_df2))
ds <- detectseparation::detect_separation(X, y)
print(ds)
```

Efectivamente nos enfrentamos a un problema de separación real, lo cual puede traducerse en inexistencia de coeficientes finitos. En consecuencia, decidimos reestimar el mismo modelo mediando regresión logística con reducción de sesgo con un enfoque Firth. 

```{r}
library(brglm2)

m_firth <- glm(
  formula(m_completo),
  data   = df,
  family = binomial("logit"),
  method = "brglmFit",
)

summary(m_firth)
```

En un primer intento nuestro modelo no alcanzó convergencia, lo que se traduce en estimaciones inestables, de manera que se procede a ajustar parámetros de control de las iteraciones:

```{r}
library(brglm2)

ctrl <- brglm2::brglmControl(
  maxit = 2000,          # + iteraciones (default 100)
  slowit = 0.5,          # pasos más pequeños
  response_adjustment = 0.5  # arranque con ajuste tipo 0.5 en binomial
)

m_firth2 <- glm(
  formula(m_completo),
  data   = df,
  family = binomial("logit"),
  method = "brglmFit",
  type   = "AS_mean",
  control = ctrl
)

cat("Convergencia:", m_firth2$converged)
cat("\nNúmero de iteraciones:", m_firth2$iter)
summary(m_firth2)

```

Gracias a las especificacines de control el modelo ahora sí ha alcanzado convergencia. Todavía observamos algunos SE grandes, lo que indica estimaciones débiles para esos niveles, pero una mejora considerable frente al modelo anterio sin este ajuste Firth.

Veamos una compración de SE, y otro test de separación, para el modelo sin ajuste 'm_completo' y el modelo ajustado 'm_firth2':

```{r}
se_ml <- summary(m_completo)$coefficients[,2]
se_fi <- summary(m_firth2)$coefficients[,2]

cat("\nTop 10 SE (MLE):\n")
print(head(sort(se_ml, decreasing=TRUE), 10))

cat("\nTop 10 SE (Firth/AS):\n")
print(head(sort(se_fi, decreasing=TRUE), 10))

cat("Separación:\n")
m_firth2_df2 <- update(m_firth2, data = df2)

X <- model.matrix(m_firth2_df2)
y <- model.response(model.frame(m_firth2_df2))
ds <- detectseparation::detect_separation(X, y)
print(ds)
```

Podemos ver como la presencia de separación no se ha eliminado, cual era esperable ya que la reducción de sesgo Firth no cambia la estructura de separación de los dato, pero sí asegura que nuestro modelo es robusto frente a ella. Podemos comprobarlo viendo la significativa reducción de los SE.

**Colinealidad**

Una vez controlada la separación observamos volvamos a realizar las pruebas de colinealidad:

```{r}
library(car)
vif(m_firth2)
```

Una vez manejada la separación, se elimina la existencia de colinealidad grave y los términos afectados presentan ahora colinealidad moderada que no refleja una preocupación real. Dado uestro objetivo descriptivo, se mantiene el modelo con todos sus términos. 

**Resumen**

Finalmente se concluye con el modelo final de tipo regresión logística incluyendo reducción de sesgo Firth.

```{r}
ctrl <- brglm2::brglmControl(
  maxit = 2000,          
  slowit = 0.5,          
  response_adjustment = 0.5  
)

m_principal <- glm(
  formula(exito ~
    fecha_est + log_ancho +
    tam_cat + orientacion +
    soporte_grp + tecnica + sop_montaje +
    serie +
    soporte_grp:tam_cat),
  data   = df,
  family = binomial("logit"),
  method = "brglmFit",
  type   = "AS_mean",
  control = ctrl
)

summary(m_principal)
```

## Validación


```{r}
summary(m_principal)$null.deviance
summary(m_principal)$deviance
nobs(m_principal)
# Pseudo R² de McFadden
1 - summary(m_principal)$deviance / summary(m_principal)$null.deviance

```
Observamos que la deviance es menor que la del modelo nulo, lo que nos esta indicando que al introducir las variables explicativas tenemos una mejora del modelo. Las covariables introducidas aportan informacion para estimar la probabilidad. Por lo qeu el modelo está bien ajustado

**Capacidad discriminativa**

```{r}
# Probabilidades predichas
prob_principal <- predict(m_principal, type = "response")

# Curva ROC
roc_principal <- roc(df$exito, prob_principal)

# AUC
auc(roc_principal)

# Gráfico ROC
plot(roc_principal,
     main = "Curva ROC – Modelo principal",
     col = "black",
     lwd = 2)
abline(a = 0, b = 1, lty = 2, col = "gray")
library(dplyr)

calibracion <- data.frame(
  obs = df$exito,
  pred = prob_principal
) %>%
  mutate(decil = ntile(pred, 10)) %>%
  group_by(decil) %>%
  summarise(
    prob_predicha = mean(pred),
    prob_observada = mean(obs),
    n = n()
  )

calibracion
plot(calibracion$prob_predicha,
     calibracion$prob_observada,
     xlab = "Probabilidad predicha media",
     ylab = "Proporción observada de éxito",
     main = "Calibración del modelo principal",
     pch = 19)

abline(0, 1, lty = 2, col = "red")

```

**Residuos del modelo**

```{r}
res_pearson <- residuals(m_principal, type = "pearson")
summary(res_pearson)

plot(prob_principal, res_pearson,
     xlab = "Probabilidad predicha",
     ylab = "Residuos de Pearson",
     main = "Residuos de Pearson vs probabilidad predicha")
abline(h = 0, lty = 2)

```

```{r}
cook <- cooks.distance(m_principal)
plot(cook, type = "h",
     main = "Distancia de Cook – Modelo principal",
     ylab = "Cook's distance")
abline(h = 4 / length(cook), lty = 2, col = "red")
which(cook > 4 / length(cook))
```

El análisis de los residuos nos indica que no tenemos patrones ni desviaciones que nos sugieran que el modelo esta mal especificado. 
Con las medidas de influencia observamos qeu no hay observaciones individuales que ejerzan una gran influencia sobre la estimación de los parametros. 

Los resultados nos presentan estabilidad y robustez en las estimaciones del modelo.

**Multicoleinealidad**

```{r}
vif(m_principal)
```


Observamos quelas variables explicativas no presentan problemas de multicolinealidad.


El modelo `m_principal` se considera adecuado y fiable para predecir la probabilidad de éxito.

## Modelos alternativos

En esta sección se proponen estructuras de modelos que fueron descartadas como opciones a modelo principal pero que por interés interpretativo se ajustan igualmente. Primero presentaremos las propuestas y después serán reestimadas utilizando reducción de sesgo Firth cuando sea necesario.

**Modelo simplificado**

Dada la complejidad y posible separación debida a la interacción "soporte_grp x tam_cat", aunque ya se controló adecuadamente, se ha decidido estudiar también la posibilidad del modelo simplificado sin interacciones:

```{r}
m_reducido <- glm(
  exito ~
    fecha_est + log_ancho +
    tam_cat + orientacion +
    soporte_grp + tecnica + sop_montaje +
    serie,
  data = df,
  family = binomial(link = "logit")
)
```

**Variable tema**

Dado el interés interpretativo de tema, y visto que sí aporta información adicional pero incrementa fuertemente la complejidad (muchos niveles), su inclusión se analiza en esta sección de modelos alternativos siguiendo las siguientes estrategias:

1) Un modelo con tema ajustado por el conjunto completo de covariables del modelo principal

2) Un modelo con tema sin el bloque de material/técnica/montaje para estimar una asociación más global

3) Adicionalmente, una versión parsimoniosa usando log(area) lineal para cada caso anterior

De esta manera se explorará el efecto de tema tanto controlando las covariables de técnica/soporte/montaje como sin ellas para, de esta manera, poder obtener también una estimación global de su asociación con la respuesta. Esta decisión viene dada por consecuencia de nuestros objetivos e hipótesis principales. En un inicio se planteó la posibilidad de que la iconografía de la pintura podía estar relacionada con el cumplimiento de la razón áurea, por esta razón queremos explorar el efecto global de esta variable "tema", aun sabiendo que el efecto de técnica y soporte pudiera estar incluido en la relación, ya que este modelo no pretende estimar un efecto causal directo sino capturar asociación total que puede incluir diferencias mediadas por técnica/soporte. Por otra parte. Con el objetivo de no sesgar totalmente la interpretación, también se estudiará el efecto en conjunto con estas variables: "soporte_grp" y "tecncia", las cuales también eran de interés. Finalmente se contempla la posibilidad de cambiar la especificación del tamaño por su versión continua lineal (log(area)) con el objetivo de simplemente controlar el efecto del tamaño, pero sin interés interpretativo en esta sección.


**Ajsute de modelos**

Procedemos a ajustar todos los modelos candidatos

```{r}
# =========================================================
# MODELOS ALTERNATIVOS CON TEMA (resumen compacto)

# =========================================================
# 1) ESPECIFICACIÓN DE MODELOS (sin summary)
# =========================================================
cat("\n==============================\n1) ESPECIFICACION DE MODELOS\n==============================\n")

# Modelo final principal (sin tema, con Bloque 3, tamaño categórico)
m_final <- glm(
  exito ~ ns(fecha_est, 3) + log_ancho + tam_cat + orientacion +
    soporte_grp + tecnica + sop_montaje + serie,
  data = df, family = binomial(link = "logit")
)
cat("\n[m_final] creado: ajuste completo + tam_cat (SIN tema)\n")

# Ajuste completo + tema (tam_cat)
mT_full_tam <- update(m_final, . ~ . + tema)
cat("[mT_full_tam] creado: ajuste completo + tam_cat (CON tema)\n")

# Modelo final equivalente con log_area (sin tema)
m_final_area <- glm(
  exito ~ ns(fecha_est, 3) + log_ancho + log_area + orientacion +
    soporte_grp + tecnica + sop_montaje + serie,
  data = df, family = binomial(link = "logit")
)
cat("[m_final_area] creado: ajuste completo + log_area (SIN tema)\n")

# Ajuste completo + tema (log_area)
mT_full_area <- update(m_final_area, . ~ . + tema)
cat("[mT_full_area] creado: ajuste completo + log_area (CON tema)\n")

# Sin Bloque 3 + tam_cat (sin tema)
m_noB3_tam <- glm(
  exito ~ ns(fecha_est, 3) + log_ancho + tam_cat + orientacion + serie,
  data = df, family = binomial(link = "logit")
)
cat("[m_noB3_tam] creado: SIN Bloque 3 + tam_cat (SIN tema)\n")

# Sin Bloque 3 + tema (tam_cat)
mT_noB3_tam <- update(m_noB3_tam, . ~ . + tema)
cat("[mT_noB3_tam] creado: SIN Bloque 3 + tam_cat (CON tema)\n")

# Sin Bloque 3 + log_area (sin tema)
m_noB3_area <- glm(
  exito ~ ns(fecha_est, 3) + log_ancho + log_area + orientacion + serie,
  data = df, family = binomial(link = "logit")
)
cat("[m_noB3_area] creado: SIN Bloque 3 + log_area (SIN tema)\n")

# Sin Bloque 3 + tema (log_area)
mT_noB3_area <- update(m_noB3_area, . ~ . + tema)
cat("[mT_noB3_area] creado: SIN Bloque 3 + log_area (CON tema)\n")

# =========================================================
# 2) COMPARACIONES ANOVA (mínimas, aporte de informacion)
# =========================================================
cat("\n==============================\n2) COMPARACIONES (LRT - ANOVA)\n==============================\n")

cat("\n[2.1] Aporte de tema (ajuste completo, tam_cat): m_final vs mT_full_tam\n")
print(anova(m_final, mT_full_tam, test = "Chisq"))

cat("\n[2.2] Aporte de tema (ajuste completo, log_area): m_final_area vs mT_full_area\n")
print(anova(m_final_area, mT_full_area, test = "Chisq"))

cat("\n[2.3] Aporte de tema (SIN Bloque 3, tam_cat): m_noB3_tam vs mT_noB3_tam\n")
print(anova(m_noB3_tam, mT_noB3_tam, test = "Chisq"))

cat("\n[2.4] Aporte de tema (SIN Bloque 3, log_area): m_noB3_area vs mT_noB3_area\n")
print(anova(m_noB3_area, mT_noB3_area, test = "Chisq"))
```

Para comezar podemos ver que tema siempre resulta significativo en cunato aprte de información, es decir, independientemente de como controlemos el tamaño y de si incluimos o no el BLoque 3 (tecnica/soporte/montaje), tema añade información. Este resultado avala nuestra intención de realizar esta rección para interpretar la asociación de la iconografía con el cumplimeinto de la razón aurea.

**Comparación de modelos**

Para decidir que modelo o modelos interpretar utilizaremos los criterios AIC/BIC. Se muestras sus valores para cada modelo, y una tabla de incrementos, de manera que sea legible.
```{r}
# =========================================================
# 3) TABLA AIC/BIC (todos los modelos)
# =========================================================
cat("\n==============================\n3) TABLA AIC / BIC\n==============================\n")

mods <- list(
  m_final      = m_final,
  mT_full_tam  = mT_full_tam,
  m_final_area = m_final_area,
  mT_full_area = mT_full_area,
  m_noB3_tam   = m_noB3_tam,
  mT_noB3_tam  = mT_noB3_tam,
  m_noB3_area  = m_noB3_area,
  mT_noB3_area = mT_noB3_area
)

ic_tab <- data.frame(
  modelo = names(mods),
  df     = sapply(mods, function(m) attr(logLik(m), "df")),
  AIC    = sapply(mods, AIC),
  BIC    = sapply(mods, BIC),
  row.names = NULL
)

print(ic_tab[order(ic_tab$AIC), ])
```


Dado que pretendemos explorar la asociacion de tema tanto controlando por las covariables del BLoque 3 como sin ellas, seleccionaremos de cada una la que proporcione mejores valores de AIC/BIC. 

```{r}
# =========================================================
# Dataframe de deltas (con tema - sin tema) para AIC y BIC
# =========================================================

delta_ic <- data.frame(
  situacion = c(
    "Ajuste completo + tam_cat",
    "Ajuste completo + log_area",
    "Sin Bloque 3 + tam_cat",
    "Sin Bloque 3 + log_area"
  ),
  modelo_sin_tema = c("m_final", "m_final_area", "m_noB3_tam", "m_noB3_area"),
  modelo_con_tema = c("mT_full_tam", "mT_full_area", "mT_noB3_tam", "mT_noB3_area"),
  AIC_sin = c(AIC(m_final),      AIC(m_final_area),  AIC(m_noB3_tam),  AIC(m_noB3_area)),
  AIC_con = c(AIC(mT_full_tam),  AIC(mT_full_area),  AIC(mT_noB3_tam), AIC(mT_noB3_area)),
  BIC_sin = c(BIC(m_final),      BIC(m_final_area),  BIC(m_noB3_tam),  BIC(m_noB3_area)),
  BIC_con = c(BIC(mT_full_tam),  BIC(mT_full_area),  BIC(mT_noB3_tam), BIC(mT_noB3_area)),
  stringsAsFactors = FALSE
)

# Deltas: (con tema - sin tema)
delta_ic$delta_AIC <- delta_ic$AIC_con - delta_ic$AIC_sin
delta_ic$delta_BIC <- delta_ic$BIC_con - delta_ic$BIC_sin

# (Opcional) Redondeo para informe
delta_ic$AIC_sin   <- round(delta_ic$AIC_sin, 3)
delta_ic$AIC_con   <- round(delta_ic$AIC_con, 3)
delta_ic$BIC_sin   <- round(delta_ic$BIC_sin, 3)
delta_ic$BIC_con   <- round(delta_ic$BIC_con, 3)
delta_ic$delta_AIC <- round(delta_ic$delta_AIC, 3)
delta_ic$delta_BIC <- round(delta_ic$delta_BIC, 3)

# Mostrar tabla ordenada (por mejora AIC: más negativo = mejor)
delta_ic <- delta_ic[order(delta_ic$delta_AIC), ]

delta_ic
delta_ic[c("situacion", "delta_AIC", "delta_BIC")]
```

Podemos ver que en ambos casos, con la inclusión del Bloque 3 (tecnica/soporte/montaje) o sin ella, los modelos preferibles son aquellos con una especificación categórica del tamaño, es decir, utilizando "tam_cat" en vez de "area". Por esta razón queda eliminada la opción alternativa que se había planteado en relación al tamaño.

Los modelos finales que se utilizaran para interpretar la asociación de "tema" son 'mT_full_tam' y 'mT_noB3_tam'.

**Modelos alternativos finales**

Modelos alternativos finales:
```{r}
# modelo reducido (sin interacciones)
mA1 <- m_reducido

# tema ajustado
mA2 <- mT_full_tam

# tema global
mA3 <- mT_noB3_tam
```

Para evaluar la el posibles ajuste ediante Firth, estudiaremos la separación de los 3 modelos:

```{r}
cat("Separación para mA1 (sin interacciones):\n")
mA1_df2 <- update(mA1, data = df2)

X <- model.matrix(mA1_df2)
y <- model.response(model.frame(mA1_df2))
ds <- detectseparation::detect_separation(X, y)
print(ds)

cat("Separación para mA2 (tema ajustado):\n")
mA2_df2 <- update(mA2, data = df2)

X <- model.matrix(mA2_df2)
y <- model.response(model.frame(mA2_df2))
ds <- detectseparation::detect_separation(X, y)
print(ds)

cat("Separación para mA3 (tema global):\n")
mA3_df2 <- update(mA3, data = df2)

X <- model.matrix(mA3_df2)
y <- model.response(model.frame(mA3_df2))
ds <- detectseparation::detect_separation(X, y)
print(ds)
```

Vemos que no exite presencia de separación en ninguna de los modelos por lo que continuamos, para ellos, mediante el enlace logit sin necesidad de ajuste adicional

**Validación**

Validacion modelos alternativos, 

```{r}
prob_mT_full   <- predict(mT_full_tam, type = "response")
prob_mT_noB3   <- predict(mT_noB3_tam, type = "response")
```

```{r}
c(mT_full   = summary(mT_full_tam)$deviance,
  mT_noB3   = summary(mT_noB3_tam)$deviance)
pseudoR2 <- function(m) {
  1 - summary(m)$deviance / summary(m)$null.deviance
}

c(
  mT_full = pseudoR2(mT_full_tam),
  mT_noB3 = pseudoR2(mT_noB3_tam)
)
```
Observamos que ambos modelos alternativos presentan valores de desviacion y psudo-$R^2$ similares, loq ue indica que no alteran la capacidad del modelo. Son practicamente iguales por lo que la mejora es muy pequeña.

```{r}
AIC(mT_full_tam, mT_noB3_tam)
BIC(mT_full_tam, mT_noB3_tam)
```

Con los valores AIC i BIC detectamos lo mismo, que el modelo `mT_full_tam` es ligeramente mejor que el modelo `mT_noB3_tam`.

**Capacidad discriminativa**

```{r}
roc_mT_full   <- roc(df$exito, prob_mT_full)
roc_mT_noB3   <- roc(df$exito, prob_mT_noB3)
auc(roc_mT_full)
auc(roc_mT_noB3)
```

```{r}
plot(roc_mT_full, col = "blue", lwd = 2, main = "Curvas ROC – Modelos comparados")
plot(roc_mT_noB3, col = "red",  lwd = 2, add = TRUE)

legend("bottomright",
       legend = c("Modelo principal", "mT_full_tam", "mT_noB3_tam"),
       col = c( "blue", "red"),
       lwd = 1)

```
Con la grafica ROC vemos qeu ambos modelos se sobreponen a la media, lo que nos sugiere que no introduzcamos variables adicional ni excluyamos variables, ya que no generaran mejoras apreciables para el modelo.

**Residuos del modelo**
```{r}
res_pearson <- residuals(mT_full_tam, type = "pearson")
summary(res_pearson)

plot(prob_principal, res_pearson,
     xlab = "Probabilidad predicha",
     ylab = "Residuos de Pearson",
     main = "Residuos de Pearson vs probabilidad predicha")
abline(h = 0, lty = 2)

res_pearson <- residuals(mT_noB3_tam, type = "pearson")
summary(res_pearson)

plot(prob_principal, res_pearson,
     xlab = "Probabilidad predicha",
     ylab = "Residuos de Pearson",
     main = "Residuos de Pearson vs probabilidad predicha")
abline(h = 0, lty = 2)
```

Los residuos no muestran patrones ni grandes desviaciones que nos indiquen problemas de especificacion de los modelos. 

**Multicolinealidad**

```{r}
vif(mT_full_tam)
vif(mT_noB3_tam)
```
Los modelos alternativos no presentan de problemas de multicolinealidad.

Confirmamos que los modelos no aportan ventajas claras respecto al modelo principal en la prediccion de la probabilidad del éxito del cuadro.


# RESULTADOS

En esta sección presentamos los resultados correspondientes al modelo escogido (m_principal), después de analizar multiples modelos y las diferentes variables de la base de datos este es el modelo que presenta un mejor equilibrio entre la capacidad explicativa, parsimonia e interpretación, 

El modelo se trata de un modelo de regressión logística binaria, estimado sobre una submuestra de 7002 pinturas. La variable dependiente es el éxito (binaria). Las variables explicativas las hemos distribuido en 3 bloques según sus características.

Para identificar cual es el mejor modelo para predecir el exito del cuadro, nos hemos basado en variables explicativas separadas en cinco grupos, las referentes a la datación y el control de incertidumbre (fecha_est y fecha_ancho), las referentes a la morfologia (area y orientación) y las referentes a al material y la técnica usada (soporte y tecnica), laa rerferente a la Inconografia (tema) y las referentes a autoria y serie (tipo_autor y serie). De todo el conjunto de bloques hemos analizado su nivel de significación en el modelo y hemos descartado del modelo final las variables tema y tipo_autor. Otras variables significativas las hemos transformado a logaritmicas o categorizado.

```{r}
sum<-summary(m_principal)
```

## Interpretación de coeficientes

**Variables continuas**

La variable `fecha_est`tiene un coeficiente positivo i significativo (0.00275), indicando que las obras realizadas en fechas más recientes presentan una mayor probabilidad de éxito. 
```{r}
(OR_f<-exp(100*sum$coefficients["fecha_est", "Estimate"]))
```
Cada 100 años que pasan, la pintura tiene un 31.7% más de probabilidad de tener éxito, siempre comparandola con 100 años menos.

En cambio, referente también a la datación, la variable `log_ancho` no es estadísticamente significativa, lo que nos sirve para tener un criterio de control del efecto temporal.

**Variables categóricas**

El tamaño de la obra `tam_cat` coge como referencia la categoria pequeño, en base a ella las otras medidas estimadas son mediano y grande. El tamaño del cuadro mediano no proporciona una diferencia significativa respecto a los cuadros pequeños. En cambio, las obras grandes si que presentan un efecto en el éxito (0.918).

```{r}
(OR_t<-exp(sum$coefficients["tam_catgrande","Estimate"]))
```

El odds ratio nos indica que las obras de tamaño grande multiplican por 2.69 las probabilidades de éxito respecto a las pequeñas. Por lo que el tamaño si que es un factor importante para el modelo.

En lo que respeta a la orientación, tomamos como referencia la orientación vertical. 

```{r}
(OR_o<-exp(sum$coefficients["orientacionhorizontal","Estimate"]))
```
Las obras con una orientación horizontal presentan un 33.11% más de probabilidades de éxito que las verticales.

La variable soporte hace referencia al tipo de soporte usado, como referencia se coge el lienzo, en comparación con este tenemos Tabla/Panel y Otros que son significativos y Metal y Mural que no son estadísticamente significativos. 
```{r}
(OR_stp<-exp(sum$coefficients["soporte_grpTabla/Panel","Estimate"]))
(OR_so<-exp(sum$coefficients["soporte_grpOtros","Estimate"]))
```
Los cuadros realizados sobre tabla o panel presentan un 79.8% más de probabilidades de éxito que el lienzo mientras que los soportes otros tienen una probabilidad de -53.9% de éxito respecto los lienzos.

La técnica con la que se pintaron las obras no presentan significación entre ellas, lo que nos indica que es independiente como se ha pintado el cuadro para nuestro modelo.

La presencia o no de soporte de montaje `sop_montaje` es significativo para el modelo.

```{r}
(OR_so<-exp(sum$coefficients["sop_montajesi","Estimate"]))
```
Las pinturas que cuentan con soporte de montaje tienen 2.2 veces más probabilidades de éxito que aquellas que no lo tienen.

Si pertenecen a una serie es también importante en nuestro modelo. Las obras que pertenecen a una serie presentan un 32.28% más de probabilidades de éxito que las que son independientes.

```{r}
(OR_ser<-exp(sum$coefficients["seriesi","Estimate"]))
```
Finalmente tenemos las interacciones entre las variables tamaño y tipo de soporte de las cuales tan solo es significativa la interacción grande con Tabla/Panel, la cual reduce la probabilidad de éxito.

En conjunto podemos interpretar que en la estimación de la probabilidad del exito intervienen diversos factores, temporal, morfologico, material y estructural. 

## Resumen de los resultados

Analizamos ahora gráficamente las predicciones de la probabilidad de éxito para cada variable donde las demas covariables las estamos obviando. Asi comparamos como afecta cada una en el modelo de predicción.

```{r}
plot_predictions(
  m_principal,
  condition = "fecha_est",
  vcov = TRUE
) +
  labs(
    x = "Fecha estimada de ejecución",
    y = "Probabilidad predicha de éxito",
    title = "Probabilidad de éxito según la fecha estimada"
  )

```
Observamos que a más actual es la obra, mayor probabilidad de éxito.
```{r}
plot_predictions(
  m_principal,
  condition = "tam_cat",
  vcov = TRUE
) +
  labs(
    x = "Tamaño de la obra",
    y = "Probabilidad predicha de éxito",
    title = "Efecto del tamaño sobre la probabilidad de éxito"
  )
```
En el caso del tamaño de la obra separado por categorias vemos como la diferencia entre pequeño y mediano es practicamente nula e indicanto una probabilidad muy baja, en cambio los cuadros con area grande tienen una probabilidad de éxito mucho mayor. 

```{r}
plot_predictions(
  m_principal,
  condition = "orientacion",
  vcov = TRUE
) +
  labs(
    x = "Orientación",
    y = "Probabilidad predicha de éxito",
    title = "Efecto de la orientación sobre la probabilidad de éxito"
  )

```
En lo que respeta a la orientación, las obras horizontales tienen una mayor probabilidad de éxito que las verticales.

```{r}
plot_predictions(
  m_principal,
  condition = "sop_montaje",
  vcov = TRUE
) +
  labs(
    x = "Soporte de montaje",
    y = "Probabilidad predicha de éxito",
    title = "Efecto del soporte de montaje sobre el éxito"
  )

```
Aquellos cuadros que presentan soporte de montaje tienen mayor probabilidad de éxito que los que no tienen soporte.

```{r}
plot_predictions(
  m_principal,
  condition = "soporte_grp",
  vcov = TRUE
) +
  labs(
    x = "Tipo de soporte",
    y = "Probabilidad predicha de éxito",
    title = "Probabilidad de éxito según el tipo de soporte"
  )

```

Finalmente vamos que las probabilidades según el tipo de soporte varian bastante. El lienzo tiene un intervalo de confianza muy bajo y probabilidad muy marcada. El metal vemos que no es indicativo del éxito ya que el intervalo de confianza es muy amplio llevandonos de 0.5 a -0.25. Para mural y otros tenemos un impacto menor que el lienzo y en el caso de Tabla/Panel tenemos una media similar al lienzo.

## RESULTADOS MODELOS ALTERNATIVOS

Aunque hemos cogido `m_principal` como mejor modelo para explicar la probabilidad de éxito, también hemos creado dos modelos alternativos que nos explican la probabilidad de éxito.
Estos modelos se tratan de `mT_full_tam` y `mT_noB3_tam` 

```{r}
smod1<-summary(mT_full_tam)
```

En el primer modelo alternativo hemos aplicado un modelo logit en el cual hemos añadido la variable tema de la obra para predecir el éxito y eliminado cualquier tipo de interacción entre variables.

En lo que respeta  a las variables observamos que ns(fecha_est,3) es la única variable de fecha que tiene significación en el modelo. También vemos que tenemos 3 categorias de tema que si que tienen diferencias significativas con los demás temas, que son `paisaje_lugares`, `otros` y `historia_alegoria`, todas ellas positivas en la predicción del éxito, los demás temas no son significativos.


```{r}
smod2<-summary(mT_noB3_tam)
```
El segundo modelo alternativo `mT_noB3_tam` proporciona una representación más simple y contiene las mismas variables y estructura que el modelo anterior pero eliminando las referentes al bloque de material i técnica.
Las variables que se repiten en ambos modelos siguen presentando el mismo nivel de significación, magnitud y signo, por lo que la interpretación de las variables repetidas es la misma en ambos modelos.


**Comparación entre los modelos**

```{r}
modelos_a_comparar <- list(
  "Principal" = m_principal, 
  "full_tam" = mT_full_tam,
  "noB3_tam"= mT_noB3_tam
)

modelsummary(modelos_a_comparar, 
             stars = TRUE, 
             title = "Comparación de coeficientes entre especificaciones",
             coef_rename = c("fecha_est" = "Fecha Estimada", "log_area" = "log(Área)"),
             gof_omit = "AIC|BIC|Log.Lik|RMSE",
             output = "markdown")
```

Finalmente observamos la comparación y nivel de significación de las variables y sus categorias en los tres modelos planteados, el principal y los alternativos.

# ANALISIS SECUNDARIOS

Tambien podemos usar la base de datos existente a fin de predecir otras variables de la base se datos.

Una de las variables que podemos predecir es el tamaño de los cuadros, es decir, el area de cada cuadro. Para hacerlo aplicamos un modelo de regressión simple, también analizamos sus posibles interacciones.
```{r}
m_fecha <- lm(fecha_est ~ tema + soporte_grp + tam_cat + orientacion+tipo_autor+tecnica+serie*tam_cat, data = df)
anova(m_fecha)
summary(m_fecha)
par(mfrow = c(2, 2))
plot(m_fecha)
```

Observamos que para predecir la fecha estimada del cuadro las variables tema, tipo de soporte, tamaño, orientacion, tipo de autor, tecnica, serie y la interacción entre tamaño del cuadro y serie son significativas.


# CONCLUSIONES

