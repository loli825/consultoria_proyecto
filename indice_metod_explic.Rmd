---
title: "índice, metodología y explicación dataset"
author: "Manuela Lopez Cambron, 1673688"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ÍNDICE 

1. Introducción 

1.1 Motivo del estudio

1.2 Marco teórico

1.3 Objetivos y hipótesis

1.4 Presentación de los datos

2. Gestión de datos

2.1 Manejo de valores faltantes

2.2 Transformación de variables

2.3 Creación de nuevas variables

2.4 Manejo de desbalances

3. Metodología

4. Análisis descriptivo

(abril poner los puntos)

4.? Manejo de outliers (explicación angel)

5. Análisis principal

5.1 Efectos principales

5.2 Interacciones

5.3 Diagnóstico de ajuste y correcciones

5.4 Validación del modelo (angel/marc)

5.5 Modelos alternativos y validación (validación ángel/marc)

6. Resultados (angel/marc)

6.1 Modelo principal 

6.1 Efectos marginales 

6.2 Presentación de resultados 

6.3 Interpretacion 

6.4 Resultados de los modelos alternativos

6.5 Hallazgos principales 

7. Análisis secundarios (angel/marc)

8. Conlusiones

8.1 Descubrimientos del estudio (angel/marc)

8.2 Continuidad del proyecto: limitaciones y propuestas

### INDICE EXPLICADO

1. Introducción 

1.1 Motivo del estudio

1.2 Marco teórico

1.3 Objetivos y hipótesis

1.4 Presentación de los datos

2. Presupuesto

3. Gestión de datos

3.1 Manejo de valores faltantes

3.2 Transformación de variables

3.3 Creación de nuevas variables

3.4 Manejo de desbalances

4. Análisis descriptivo

(abril poner los puntos)

3.? Manejo de outliers (explicación angel)

5. Análisis principal

5.1 Efectos principales

5.2 Interacciones

5.3 Refinamiento del modelo

5.4 Validación del modelo (angel/marc)

5.5 Modelos alternativos y validación (validación ángel/marc)

6. Resultados (angel/marc cambiad puntos o lo que querias pero estas cosas deberian estar)

6.1 Modelo principal (aquí os pondre el modelo y vosotros haceis el summary y tal)

6.1 Efectos marginales 

(aquí he pensado rollo calcular cosas interpretables a parte de los coeficientes propios del modelo, rollo como afecta cada variable es general a parte de como afectan sus niveles. cambiadle el nombre a la sección o lo que queráis para que cuadre con lo que hagais)

6.2 Presentación de resultados 

(tablas/graficos visuales resumiento todos los resultados, nada de salidas de r, poner los coefs y ls cosas del summary y las cosas que hayas calculado en efectos amrginales. solo del modelo principal)

6.3 Interpretacion 

(muy detallada, de todo lo que se os ocurra, bien explicado todo)

(igual podeis juntar 6.2 y 6.3 depende de como lo querais pantlear)

6.4 Resultados de los modelos alternativos

(lo mimso que los puntos anteriores (presentar los modelos alternativos que hay 2, efectos amrginales y resultados). h epensado poenrlo todo  junto porque es como menos importante

5.5 Hallazgos principales 

(a modo de resumen rapido de que ha salido relevante, que leyendo esto alguien pueda tener las 4 ideas principales. tanto del mdoelo principal como de lso secundarios)

6. Análisis secundarios (angel/marc)

(son modelos estudiando otras cosas que no sea el exito, rollo aprovechar la base de datos creada para estudiar más cosas. no es totalmente necesario pero si estaria guay ahcer al menos un análisis secundario con otro variable como resultado)

7. Conlusiones

7.1 Descubrimientos del estudio (angel/marc)

(mucho más explicado sin tecnicismos, en interpretación sed tecnicos y aquí es más rollo aplicado a al realidad y habria que relacionarlo aquí con los obejtivo (y hipotesis) rollo que quede bien cerrado todo en plan teniamos una idea y nos ha llevado aquí, se ha cumplido o no, lo hemso conseguido o no, etc)

7.2 Continuidad del proyecto: limitaciones y propuestas

(limitaciones: cosas que hemos hecho mal, rollo donde hemos podido poner sesgos y hacerlo modo "facil" y se podria hacer mejor o si salen inconsistencias o cosas sin sentido pues decir aqui por que puede ser. Y propuestas: ideas para estudios futuros, tenemos que hacer incapie en que hemos creado un base de datos y que puede explotarse mucho mas, rollo darnos importancia no solo por el estudio sino por las diferentes posibilidades, y pensad en algunas concretas, que da nuetsra base de datos) (aquí estaria guya relacionar el estudioq ue hemos hecho con lo que aprendimos del otro articuloq ue analizamos)

(estos dos puntos 7.1 y 7.2 minimo deberian estar pero cambiadlo como querais)


# Presentación de los datos

Para el propósito del estudio se ha decidido estudiar la coleción de obras de arte del Prado, concretamente aquellas clasificadas como pinturas. Mediante web scraping, se ha extraido la ficha técnica de las 7.117 pinturas, la cual contiene la siguiente información: 

Siempre (en todas las obras):

  - Número de catálogo (asignado por el Prado, único por obra)

  - Título

  - Fecha

Casi siempre:

  - Técnica (7.114/7.117)

  - Dimensión (7.107/7.117)

  - Procedencia (7.098/7.117)

  - Soporte (7.096/7.117)

- A veces:

  - Serie (1.415/7.117)

Muy raros:

  - Materia, Lugar de producción, Edición / Estado

Están son las variables originales de las que se disponía, y después de la correspondiente gestión de datos se ha obtenido la base de datos final con un total de 7.002 registros y 12 variables preparadas para el análisis. En el archivo original, los valores faltantes se condificaban como "0", después de su apropiada gestión, se proporciona un dataset sin valores faltantes.

**Diccionario de variables**

- exito: Indicador de cumplimiento de "razón aurea", con error del 5% (categórica binaria, 2 niveles: 0 no, 1 sí)

- area: Área de la pintura a partir de las dimensiones, tamaño en formato numérico (numérica)

- tam_cat:  Tamaño categorizado a partir del área usant cuantiles (categórica ordinal, utilizada como nominal, 3 niveles: pequena, mediano, grane)

- orientación: Forma según comparación de dimensiones (categórica nominal, 3 niveles:vertical, horizontal, cuadrado)

- soporte_grp: Agrupación de tipos de soporte en familias de material (categórica nominal, niveles: Lienzo, Tabla/Panel, Metal, Mural, Otros)

- sop_montaje: Indicador de "montaje/transferencia" detectado en el campo soporte (cotegórica binaria, 2 niveles: 0 no, 1 sí)

- tecnica: Agrupación de técnicas en grupos genéricos (categórica nominal, 3 niveles: mixta, oleo, otras)

- tipo_autor: A partir de autor/autora/autores se creó un tipo de autoría (categórica nominal, 4 niveles: hombre, mujer, varios, anonimo)

- serie: Indicador de pertenencia a serie (categórica binaria, 2 niveles: 0 no, 1 sí)

- fecha_est: Año estimado a partir de la datación convertida en intervalo, año central de este (numérica)

- fecha_ancho: Incertidumbre/ancho del intervalo temporal de datación (numérica)

- tema: Tema asignado en función de términos clave encontrados en el texto original de título (categórica, 10 niveles: religioso, mitologia, retrato_corte, historia_aleagoria, paisajes_lugares, vida_cotidiana, bodegon_floral, caza_animales, proceso_obra, otros)


## Metodología

Como enfoque general se decidieron adoptar procedimientos que permitieran contar una historia en relación a las variables que finalmente se involucren. No solo obtener resultados automatizados sinó estudiar en profundidad cómo unas variables, en presencia o no de otras, afectan a la probabilidad de observar el evento de interés. Por lo tanto, no se presentará un único modelo, pues consideramos que dado el gran alcance de nuestra base de datos, no existe un único modelo óptimo para estudiarla, sino diversas combinaciones de variables que respondan a preguntas de distinto enfoque.   

Como aprendimos en la última práctica, gracias a la lectura del artículo "A hypotesis is a liability", la persecución de nuestras hipótesis no debe ser el único objetivo de un buen estudio. Debemos recordar la importancia de trabajar los datos tanto bajo la ciencia diurna como la nocturna, de manera que mantengamos la mente y los ojos abiertos a nuevas posibilidades aunque siempre en presencia y ayuda de procedimientos y técnicas adecuadas que nos permitan analizarlos rigurosamente.

Por esta razón, se descartan los métodos de selección automática tipo stepwise con el fin de controlar cada paso interno que este tipo de procesos esconden. En su lugar, se hará uso de una filosofía de selección basada en bloques conceptuales que definen las variables. Estos bloques se introducirán uno por uno por uno de manera que se irá construyendo un modelo principal sobre el que trabajaremos pero también se irá guardando la información obtenida en cada paso no fructifero de manera que se utilizará para generar otros modelos alternativos que nos permitan estudiar la variable respuesta desde otro enfoque. Esta filosofía pretende ser adecuada para explorar al máximo nuestra base de datos y darnos información potencialmente interesante sobre todas y cada una de las variables.

Por otro lado debemos poder actuar de forma estadísticamente correcta, por lo que en esta sección se detallan los procedimientos y técnicas utilizadas, además de los criterios preestablecimos en relación a las sucesivas decisiones que se tomarán para derivar tanto el modelo principal como los alternativos.

**Regla estructural 'cuadrado'**

Primera deberemos modificar nuestra abse de datos de manera que se eliminarán las observaciones de pinturas cuadradas. Como se informó anteriormente, la categoría 'cuadrado' de la variable "orientacion" genera ceros estructurales, ya que por definición los cuadros cuadrados nunca seguirán la proporción aurea. La presencia de una categoría con ausencia completa del evento induce separación perfecta en modelos binarios, lo que puede producir estimaciones inestables o no finitas y distorsionar la estimación de efectos del resto de covariables. Por estos motivos, se restringió el análisis inferencial a la subpoblación con orientacion $\neq$ "cuadrado". Gracias a esta modificación podemos introducir la variable "orientación" sin problemas, pero la inferencia de nuestro estudio solo será aplicable a esta subpoblación. 

**Modelos y correcciones**

La base para el análisis serán Modelos Lineales Generalizados (GLZ/GLM). No se contempla la utilización de modelos mixtos dado que no hay presencia aparente de estructura por bloques. Las observaciones se consideran independientes entre sí, puesto que disponemos de una única medición de cada variable para cada obra, ni ninguna variable que naturalmente las pueda estructurar. Nuestra variable respuesta es de tipo binaria, por lo que asumiremos una distribución Binomial con enlace logit (enlace canónico de la distribución). Es decir trabajaremos en todo momento con regresiones logísticas.

Dado el desbalance y la posible separación a la que podremos enfrentarnos, se considerará añadir una reducción de sesgo con un enfoque Firth.

**Selección de efectos principales** 

Es en este punto donde se remarca la filosofía por bloques utilizada: para la selección de las covariables que formarán parte del modelo principal, y las que se mantendrán para los modelos alternativos. 

Las variables han sido clasificadas en los siguientes bloques según su interpretación conceptual:

1) Datación + incertidumbre (fecha_est, fecha_ancho)

2) Morfología (log(area), orientacion) + (tam_cat)

3) Material y tecnica (soporte_grp, tecnica) + (sop_montaje, como "control")

4) Iconografia (tema)

5) Autoría y serie (tipo_autor, serie)

Comenzaremos con un modelo nulo sobre el cual se irán añadiendo estos bloques de variables sucesivamente y uno por uno. En cada paso se valorará si el bloque demuestra o no mejora respecto el modelo anterior. Se analizará si éste aporta información adicional mediante comparación de modelos anidados y el coste en complejidad que refleja. Si el veredicto es positivo, entonces se mantendrá el bloque en el modelo principal y se añadirá el siguiente sobre este. Si un bloque o una variable no demuestra aportar información al modelo ajustado por los anteriores, se descartará automáticamente. Si por el contrario existe aporte de información pero coste de complejidad excesivo, se mantendra el bloque para ser utilizado en un futuro modelo alternativo.

**Selección de interacciones**

Una vez escogidas las covariables principales, se procederá a determinar la inclusión de algunas interacciones al modelo principal. No se considerarán interacciones de dos variables. Aunque algunas de ellas son de interés para nosotros con el fin de dar respuesta a nuestras hipótesis, la principal herramiento para su selección serán los gráficos de analisis descriptivo, donde se hará una primera criva. Las candidatas serán sometidas a una segunda criva en esta sección del análisis de interacciones. Primeramente se graficarán los gráficos de interacción de los modelos con cada una de ellas. Seguidamente, aquellas que resulten significativas se verificarán mediante la inspección de sus combinaciones de niveles para descartar relaciones engañosas devido a celdas vacías (ya que se han observado incidios de desbalances muchas de ellas). Finalmente las seleccionadas se someterán a pruebas formales mediante modelos anidados.

**Trnasformación de variables**

Según se visualice en el análisis descriptivo, se decidirá si algunas de las variables continuas deben ser transformadas o no para entrar en el modelo.

Además, para estas variables se considerarán siempre tanto una especificación lineal como una flexible mediante spline con 3 nudos, ya que no se espera una relación que exista una relación del todo lineal entre "fecha_est" y "area" con la respuesta, pero ambas son variables que queremos que entren en el modelo. Abas especificaciones se compararan con modelos anidados.

**Comparación de modelos**

Para las comparaciones de modelos anidados se empleará el test de razón de verosimilitudes (LRT) basado en diferencia de devianza con distribución $\chi^2$. Con una confianza del 95% en el análisis de efectos principales y con una confianza del 99% en el análisis de interacciones.

También de emplearán los criteriors de información Akaike y Bayesiano (AIC/BIC) para evaluar el coste de complejidad, consideran un aumento de 2 puntos como significativo.

Para cada modelo anidado se proporcionará también el resumen estadístico de este (summary) para visualizar rápidamente si vemos indicios problemáticos, concretamente para verificar que los errore estándares de los coeficientes no se disparán y que el modelo se ha ajustado correctamente.

**Validación de modelos**

Para la validación de los modelos se ha analizado la desviación i pseudoR2. La capacidad discriminativa mediante el área bajor la curva y las gráficas ROC. Analizado los residuos de los modelos y revisado los problemas de multicolinealidad mediante el VIF y el GVIF ajustado.

Para el modelo principal también se ha analizado la distància de cook al detectar mediante el summary que havia interacciones influyentes. Posteriormente, se ha creado la tabla para detectar las causas.
